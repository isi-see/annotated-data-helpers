---
title: "annotation-helpers-readme"
output: html_document
date: "2025-01-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=100)

library(tidyverse)
library(dplyr)
library(janitor)
```

## Overview

This is a collection of different helper functions I have used in various data labeling projects.
In these projects, individual data points are annotated by several data annotators/reviewers, and these reviewers each give a label judgment to the data.
These helpers are mostly for string tidying, wrangling, and processing.

## Application 
These functions/scripts are intended to

- **create human-reviewable outputs**, e.g. for further manual review in a spreadsheet (`human_review_helpers.R`)
- **aggregate** all given judgments to a final *label* or label set for the datapoint (majority label, union of labels) (`label_aggregation_helpers.R`)
- **check** the judgments given by individual annotators to review their performance, or compare to "gold" labels (`annotator_review_helpers.R`)

## Expected format
These functions expect the labeled datasets in *CSV format*.

Different *dummy datasets* are provided to showcase the expected input and output for different formats (**radio buttons** vs **checkboxes**).

Context: On common data labeling platforms, annotators give their judgments in the following format:

![Example UI for Radio buttons](radio_buttons_UI_example.jpg)

![Example UI for Checkboxes](checkboxes_UI_example.jpg)
 

The provided dummy datasets mimic the expected formats:

```{r echo=FALSE}

dummy_data1 <- read.csv("dummy_data_aggr-output.csv", stringsAsFactors = F)
dummy_data2 <- read.csv("dummy_data_by_annotator.csv", stringsAsFactors = F)

print("Dummy dataset1 (one row per datapoint):")
glimpse(dummy_data1)

print("Dummy dataset2 (one row per judgment): ")
glimpse(dummy_data2)
```
